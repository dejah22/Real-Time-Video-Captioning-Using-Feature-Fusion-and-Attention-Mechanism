{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.9 python3.9-distutils python3.9-dev -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqHLXv89YAwC",
        "outputId": "d22753aa-9e54-42b5-e010-76ab564f0fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.81)] [\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.81)] [\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,765 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,573 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,138 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,470 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,163 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,268 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,976 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,159 kB]\n",
            "Fetched 31.9 MB in 2s (14.5 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.9 libpython3.9-dev libpython3.9-minimal libpython3.9-stdlib\n",
            "  python3.9-lib2to3 python3.9-minimal\n",
            "Suggested packages:\n",
            "  python3.9-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.9 libpython3.9-dev libpython3.9-minimal libpython3.9-stdlib\n",
            "  python3.9 python3.9-dev python3.9-distutils python3.9-lib2to3\n",
            "  python3.9-minimal\n",
            "0 upgraded, 9 newly installed, 0 to remove and 6 not upgraded.\n",
            "Need to get 12.2 MB of archives.\n",
            "After this operation, 46.6 MB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9-minimal amd64 3.9.23-1+jammy1 [837 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-minimal amd64 3.9.23-1+jammy1 [2,075 kB]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9-stdlib amd64 3.9.23-1+jammy1 [1,842 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9 amd64 3.9.23-1+jammy1 [1,904 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9-dev amd64 3.9.23-1+jammy1 [4,630 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9 amd64 3.9.23-1+jammy1 [93.1 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-dev amd64 3.9.23-1+jammy1 [500 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-lib2to3 all 3.9.23-1+jammy1 [127 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-distutils all 3.9.23-1+jammy1 [193 kB]\n",
            "Fetched 12.2 MB in 2s (6,354 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 9.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.9-minimal:amd64.\n",
            "(Reading database ... 122127 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.9-minimal_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9-minimal:amd64 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-minimal.\n",
            "Preparing to unpack .../1-python3.9-minimal_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.9-minimal (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.9-stdlib:amd64.\n",
            "Preparing to unpack .../2-libpython3.9-stdlib_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9-stdlib:amd64 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.9:amd64.\n",
            "Preparing to unpack .../3-libpython3.9_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9:amd64 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.9-dev:amd64.\n",
            "Preparing to unpack .../4-libpython3.9-dev_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9-dev:amd64 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9.\n",
            "Preparing to unpack .../5-python3.9_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.9 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-dev.\n",
            "Preparing to unpack .../6-python3.9-dev_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.9-dev (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-lib2to3.\n",
            "Preparing to unpack .../7-python3.9-lib2to3_3.9.23-1+jammy1_all.deb ...\n",
            "Unpacking python3.9-lib2to3 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-distutils.\n",
            "Preparing to unpack .../8-python3.9-distutils_3.9.23-1+jammy1_all.deb ...\n",
            "Unpacking python3.9-distutils (3.9.23-1+jammy1) ...\n",
            "Setting up libpython3.9-minimal:amd64 (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9-lib2to3 (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9-distutils (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9-minimal (3.9.23-1+jammy1) ...\n",
            "Setting up libpython3.9-stdlib:amd64 (3.9.23-1+jammy1) ...\n",
            "Setting up libpython3.9:amd64 (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9 (3.9.23-1+jammy1) ...\n",
            "Setting up libpython3.9-dev:amd64 (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9-dev (3.9.23-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and install pip for Python 3.10\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!python3.9 get-pip.py"
      ],
      "metadata": {
        "id": "VIDAnEiGYPrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c57d5dd-08f1-4122-fb4e-34b743609a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-23 06:51:07--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2279307 (2.2M) [text/x-python]\n",
            "Saving to: ‘get-pip.py’\n",
            "\n",
            "\rget-pip.py            0%[                    ]       0  --.-KB/s               \rget-pip.py          100%[===================>]   2.17M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-07-23 06:51:07 (33.1 MB/s) - ‘get-pip.py’ saved [2279307/2279307]\n",
            "\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wheel\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pip]\n",
            "\u001b[1A\u001b[2KSuccessfully installed pip-25.1.1 setuptools-80.9.0 wheel-0.45.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install your dependencies\n",
        "!python3.9 -m pip install tensorflow==2.13 keras-preprocessing==1.0.8 numpy==1.23 h5py joblib dill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnRnmCqJYTUI",
        "outputId": "c0e79861-36d5-46bb-bb3f-948b876f3e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.13\n",
            "  Downloading tensorflow-2.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting keras-preprocessing==1.0.8\n",
            "  Downloading Keras_Preprocessing-1.0.8-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting numpy==1.23\n",
            "  Downloading numpy-1.23.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting h5py\n",
            "  Downloading h5py-3.14.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting joblib\n",
            "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting dill\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow==2.13)\n",
            "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow==2.13)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=23.1.21 (from tensorflow==2.13)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow==2.13)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.13)\n",
            "  Downloading grpcio-1.73.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow==2.13)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow==2.13)\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting packaging (from tensorflow==2.13)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.13)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.13) (80.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow==2.13) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow==2.13)\n",
            "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting wrapt>=1.11.0 (from tensorflow==2.13)\n",
            "  Downloading wrapt-1.17.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.13)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (3.3.6)\n",
            "Collecting requests<3,>=2.21.0 (from tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (0.45.1)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading charset_normalizer-3.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/lib/python3/dist-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow==2.13) (4.6.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13) (3.2.0)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading tensorflow-2.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.0.8-py2.py3-none-any.whl (59 kB)\n",
            "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading grpcio-1.73.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
            "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Downloading h5py-3.14.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
            "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
            "Downloading wrapt-1.17.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Installing collected packages: libclang, flatbuffers, wrapt, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, packaging, opt-einsum, numpy, MarkupSafe, keras, joblib, idna, grpcio, google-pasta, gast, dill, charset_normalizer, certifi, cachetools, astunparse, absl-py, werkzeug, rsa, requests, pyasn1-modules, keras-preprocessing, h5py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
            "\u001b[2K  Attempting uninstall: MarkupSafe\n",
            "\u001b[2K    Found existing installation: MarkupSafe 2.0.1\n",
            "\u001b[2K    Uninstalling MarkupSafe-2.0.1:\n",
            "\u001b[2K      Successfully uninstalled MarkupSafe-2.0.1\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38/38\u001b[0m [tensorflow]\n",
            "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 absl-py-2.3.1 astunparse-1.6.3 cachetools-5.5.2 certifi-2025.7.14 charset_normalizer-3.4.2 dill-0.4.0 flatbuffers-25.2.10 gast-0.4.0 google-auth-2.40.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.73.1 h5py-3.14.0 idna-3.10 joblib-1.5.1 keras-2.13.1 keras-preprocessing-1.0.8 libclang-18.1.1 numpy-1.23.0 opt-einsum-3.4.0 packaging-25.0 protobuf-4.25.8 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-2.32.4 requests-oauthlib-2.0.0 rsa-4.9.1 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.1.0 typing-extensions-4.5.0 urllib3-2.5.0 werkzeug-3.1.3 wrapt-1.17.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.9 -m pip show h5py\n",
        "!python3.9 --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdsHBDI5dAPf",
        "outputId": "d7f1dcc5-198a-4225-e2af-9c5d3d44e42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: h5py\n",
            "Version: 3.14.0\n",
            "Summary: Read and write HDF5 files from Python\n",
            "Home-page: https://www.h5py.org/\n",
            "Author: \n",
            "Author-email: Andrew Collette <andrew.collette@gmail.com>\n",
            "License-Expression: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.9/dist-packages\n",
            "Requires: numpy\n",
            "Required-by: tensorflow\n",
            "Python 3.9.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5sK-Bp8PYPz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFzDut_SPV4F",
        "outputId": "923a0b7a-2a39-480e-b320-95a432183786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "mount success\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('mount success')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cal.py\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "import joblib\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "# training features\n",
        "train_features_path = '/content/drive/Shareddrives/msvd-train-feats/train/custom_feat'\n",
        "# training captions\n",
        "train_captions_path = '/content/drive/Shareddrives/msvd-dataset/train/train_video_captions_refined.json'\n",
        "\n",
        "# validation features\n",
        "val_features_path = '/content/drive/Shareddrives/msvd-test-feats/val/custom_feat'\n",
        "# validation captions\n",
        "val_captions_path = '/content/drive/Shareddrives/msvd-dataset/val/val_video_captions_refined.json'\n",
        "\n",
        "# test features\n",
        "test_features_path = '/content/drive/Shareddrives/msvd-test-feats/test/custom_feat'\n",
        "# test captions\n",
        "test_captions_path = '/content/drive/Shareddrives/msvd-dataset/test/test_video_captions_refined.json'\n",
        "\n",
        "# label file\n",
        "TRAIN_LABEL_PATH = train_captions_path\n",
        "VAL_LABEL_PATH = val_captions_path\n",
        "\n",
        "# training labels\n",
        "with open(TRAIN_LABEL_PATH) as train_data_file:\n",
        "    train_labels = json.load(train_data_file)\n",
        "\n",
        "# validation labels\n",
        "with open(VAL_LABEL_PATH) as val_data_file:\n",
        "    val_labels = json.load(val_data_file)\n",
        "batch_size=6000\n",
        "\n",
        "class AttentionLogger(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, attention_layer):\n",
        "        super().__init__()\n",
        "        self.attention = attention_layer\n",
        "        self.log_file = \"output.csv\"\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        wt1_vals = self.attention.wt1.numpy().flatten()\n",
        "        wt2_vals = self.attention.wt2.numpy().flatten()\n",
        "        wt3_vals = self.attention.wt3.numpy().flatten()\n",
        "        wt4_vals = self.attention.wt4.numpy().flatten()\n",
        "\n",
        "        with open(self.log_file, 'a') as f:\n",
        "            f.write(f\"Epoch {epoch+1}\\n\")\n",
        "            f.write(\"wt1,\" + ','.join(map(str, wt1_vals)) + '\\n')\n",
        "            f.write(\"wt2,\" + ','.join(map(str, wt2_vals)) + '\\n')\n",
        "            f.write(\"wt3,\" + ','.join(map(str, wt3_vals)) + '\\n')\n",
        "            f.write(\"wt4,\" + ','.join(map(str, wt4_vals)) + '\\n\\n')\n",
        "\n",
        "\n",
        "class CustomAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(CustomAttention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.num_categories = 4\n",
        "        self.num_tokens = input_shape[1]\n",
        "        print(self.num_tokens)\n",
        "        # Initialize weights for each category\n",
        "        self.wt1 = self.add_weight(name='wt1', shape=(self.num_tokens,), initializer='ones', trainable=True)\n",
        "        self.wt2 = self.add_weight(name='wt2', shape=(self.num_tokens,), initializer='ones', trainable=True)\n",
        "        self.wt3 = self.add_weight(name='wt3', shape=(self.num_tokens,), initializer='ones', trainable=True)\n",
        "        self.wt4 = self.add_weight(name='wt4', shape=(self.num_tokens,), initializer='ones', trainable=True)\n",
        "\n",
        "        super(CustomAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Split the input into different categories\n",
        "        print(inputs.shape)\n",
        "        wt1_inputs = tf.slice(inputs, [0, 0, 0], [batch_size, tf.shape(inputs)[1], 4096])  # Tokens 0-4095\n",
        "\n",
        "        print('wt_inputs shapes')\n",
        "        print(wt1_inputs.shape)\n",
        "\n",
        "\n",
        "        # Gather specific tokens for wt2 and wt3 using tf.gather\n",
        "        wt2_indices = tf.constant([4100, 4106, 4112, 4118, 4124]) #confidence score\n",
        "        wt2_inputs = tf.gather(inputs, wt2_indices, axis=2)\n",
        "        wt2_inputs = tf.reshape(wt2_inputs, (batch_size,80,5))\n",
        "        print(wt2_inputs.shape)\n",
        "\n",
        "        wt3_indices = tf.constant([4101, 4107, 4113, 4119, 4125]) #classid\n",
        "        wt3_inputs = tf.gather(inputs, wt3_indices, axis=2)\n",
        "        wt3_inputs = tf.reshape(wt3_inputs, (batch_size,80,5))\n",
        "        print(wt3_inputs.shape)\n",
        "\n",
        "        #wt4_indices = tf.constant([4096:4100]+[4102:4106]+[4108:4112]+[4114:4118]+[4120:4124])\n",
        "        #coords\n",
        "        wt4_indices = tf.concat([\n",
        "          tf.range(4096, 4100, dtype=tf.int32),  # Elements from 4096 to 4099 (inclusive)\n",
        "          tf.range(4102, 4106, dtype=tf.int32),  # Elements from 4102 to 4105 (inclusive)\n",
        "          tf.range(4108, 4112, dtype=tf.int32),  # Elements from 4108 to 4111 (inclusive)\n",
        "          tf.range(4114, 4118, dtype=tf.int32),  # Elements from 4114 to 4117 (inclusive)\n",
        "          tf.range(4120, 4124, dtype=tf.int32)   # Elements from 4120 to 4123 (inclusive)\n",
        "        ], axis=0)\n",
        "        wt4_inputs = tf.gather(inputs, wt4_indices, axis=2)\n",
        "        wt4_inputs = tf.reshape(wt4_inputs, (batch_size,80,20))\n",
        "        print(wt4_inputs.shape)\n",
        "\n",
        "        # Apply weights to each category\n",
        "        wt1_expanded = tf.expand_dims(self.wt1, axis=0)\n",
        "        wt1_weighted = wt1_expanded[:, :, tf.newaxis] * wt1_inputs\n",
        "\n",
        "        wt2_expanded = tf.expand_dims(self.wt2, axis=0)\n",
        "        wt2_weighted = wt2_expanded[:, :, tf.newaxis] * wt2_inputs\n",
        "\n",
        "        wt3_expanded = tf.expand_dims(self.wt3, axis=0)\n",
        "        wt3_weighted = wt3_expanded[:, :, tf.newaxis] * wt3_inputs\n",
        "\n",
        "        wt4_expanded = tf.expand_dims(self.wt4, axis=0)\n",
        "        wt4_weighted = wt4_expanded[:, :, tf.newaxis] * wt4_inputs\n",
        "\n",
        "        # Concatenate weighted inputs\n",
        "        weighted_inputs = tf.concat([wt1_weighted, wt2_weighted, wt3_weighted, wt4_weighted], axis=2)\n",
        "\n",
        "        # Calculate attention scores\n",
        "        attention_scores = tf.reduce_sum(weighted_inputs, axis=-1, keepdims=True)\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        attention_weights = tf.nn.softmax(attention_scores, axis=1)\n",
        "\n",
        "        # Apply attention weights to inputs\n",
        "        attended_inputs = inputs * attention_weights\n",
        "\n",
        "        return attended_inputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "class VideoDescriptionTrain():\n",
        "    \"\"\"\n",
        "    Initialize the parameters for the model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # self.train_path = train_path\n",
        "        self.train_features_path = train_features_path\n",
        "        self.val_features_path = val_features_path\n",
        "        self.max_length = 10\n",
        "        self.batch_size = 6000\n",
        "        self.lr = 0.0007\n",
        "        self.epochs = 120\n",
        "        self.latent_dim = 512\n",
        "        self.num_encoder_tokens = 4126\n",
        "        self.num_decoder_tokens = 3500\n",
        "        self.time_steps_encoder = 80\n",
        "        self.time_steps_decoder = None\n",
        "        self.x_data = {}\n",
        "\n",
        "        # processed data\n",
        "        self.tokenizer = None\n",
        "        # models\n",
        "        self.encoder_model = None\n",
        "        self.decoder_model = None\n",
        "        self.inf_encoder_model = None\n",
        "        self.inf_decoder_model = None\n",
        "        self.save_model_path = '/content/drive/Shareddrives/FYP-models/CYFCAL-July2025'\n",
        "\n",
        "    # caption preprocessing\n",
        "    def preprocessing(self):\n",
        "        \"\"\"\n",
        "        Preprocessing the data\n",
        "        dumps values of the json file into a list\n",
        "        \"\"\"\n",
        "\n",
        "        # train_list contains all the captions with their video ID\n",
        "        # vocab_list contains all the vocabulary from training data\n",
        "        training_list = []\n",
        "        vocab_list = []\n",
        "        validation_list = []\n",
        "\n",
        "        #training data\n",
        "        for y in train_labels:\n",
        "          for caption in y['caption']:\n",
        "            caption = \"<bos> \" + caption + \" <eos>\"\n",
        "            # we are only using sentences whose length lie between 6 and 10\n",
        "            if len(caption.split())>10 or len(caption.split())<6:\n",
        "              continue\n",
        "            else:\n",
        "              training_list.append([caption, y['id']])\n",
        "\n",
        "        #validation data\n",
        "        for y in val_labels:\n",
        "          for caption in y['caption']:\n",
        "            caption = \"<bos> \" + caption + \" <eos>\"\n",
        "            # we are only using sentences whose length lie between 6 and 10\n",
        "            if len(caption.split())>10 or len(caption.split())<6:\n",
        "              continue\n",
        "            else:\n",
        "              validation_list.append([caption, y['id']])\n",
        "\n",
        "\n",
        "        # training_list = train_list\n",
        "        # validation_list = val_list\n",
        "\n",
        "        # print('full', len(train_list))\n",
        "        print('val len', len(validation_list))\n",
        "        print('train len', len(training_list))\n",
        "\n",
        "        for train in training_list:\n",
        "            vocab_list.append(train[0]) # vocab_list here has all captions\n",
        "\n",
        "        # caption vocabulary\n",
        "        self.tokenizer = Tokenizer(num_words=3500)\n",
        "        self.tokenizer.fit_on_texts(vocab_list)\n",
        "\n",
        "        #------ loading training features from cnn & yolo numpy files to dictionary\n",
        "\n",
        "        TRAIN_FEATURE_DIR = os.path.join(self.train_features_path, 'feat')\n",
        "        YOLO_FEATURE_DIR = os.path.join(self.train_features_path, 'yolo-feat')\n",
        "\n",
        "        # Loading all the numpy arrays at once and saving them in a dictionary\n",
        "        for filename in os.listdir(TRAIN_FEATURE_DIR):\n",
        "            cnn_file_path = os.path.join(TRAIN_FEATURE_DIR, filename)\n",
        "            yolo_file_path = os.path.join(YOLO_FEATURE_DIR, filename)\n",
        "\n",
        "            try:\n",
        "                # Check if the file is empty\n",
        "                if os.path.getsize(cnn_file_path) == 0:\n",
        "                    print(f\"Warning: CNN npy file {filename} is empty.\")\n",
        "                if os.path.getsize(yolo_file_path) == 0:\n",
        "                    print(f\"Warning: YOLO npy file {filename} is empty.\")\n",
        "\n",
        "                # Load the numpy array\n",
        "                cnn_f = np.load(cnn_file_path, allow_pickle=True)\n",
        "                yolo_f = np.load(yolo_file_path, allow_pickle=True)\n",
        "                yolo_f = yolo_f.reshape(-1, 30)\n",
        "\n",
        "                #concatenate arrays\n",
        "                combined_f = np.concatenate((cnn_f, yolo_f), axis=1)\n",
        "                print(combined_f.shape)\n",
        "\n",
        "                # Add the array to the dictionary\n",
        "                self.x_data[filename[:-4]+'.avi'] = combined_f\n",
        "\n",
        "            except Exception as e:\n",
        "                # Handle exceptions (e.g., corrupted file)\n",
        "                print(f\"Error loading file {filename}: {str(e)}\")\n",
        "\n",
        "        # Perform additional checks on x_data if needed\n",
        "        if len(self.x_data) == 0:\n",
        "            print(\"Warning: No data loaded. Check the integrity of your files.\")\n",
        "\n",
        "\n",
        "        #------ loading validation features from cnn & yolo numpy files to dictionary\n",
        "\n",
        "        TRAIN_FEATURE_DIR = os.path.join(self.val_features_path, 'feat')\n",
        "        YOLO_FEATURE_DIR = os.path.join(self.val_features_path, 'yolo-feat')\n",
        "\n",
        "        # Loading all the numpy arrays at once and saving them in a dictionary\n",
        "        for filename in os.listdir(TRAIN_FEATURE_DIR):\n",
        "            cnn_file_path = os.path.join(TRAIN_FEATURE_DIR, filename)\n",
        "            yolo_file_path = os.path.join(YOLO_FEATURE_DIR, filename)\n",
        "\n",
        "            try:\n",
        "                # Check if the file is empty\n",
        "                if os.path.getsize(cnn_file_path) == 0:\n",
        "                    print(f\"Warning: CNN npy file {filename} is empty.\")\n",
        "                if os.path.getsize(yolo_file_path) == 0:\n",
        "                    print(f\"Warning: YOLO npy file {filename} is empty.\")\n",
        "\n",
        "                # Load the numpy array\n",
        "                cnn_f = np.load(cnn_file_path, allow_pickle=True)\n",
        "                yolo_f = np.load(yolo_file_path, allow_pickle=True)\n",
        "                yolo_f = yolo_f.reshape(-1, 30)\n",
        "\n",
        "                #concatenate arrays\n",
        "                combined_f = np.concatenate((cnn_f, yolo_f), axis=1)\n",
        "                print(combined_f.shape)\n",
        "\n",
        "                # Add the array to the dictionary\n",
        "                self.x_data[filename[:-4]+'.avi'] = combined_f\n",
        "\n",
        "            except Exception as e:\n",
        "                # Handle exceptions (e.g., corrupted file)\n",
        "                print(f\"Error loading val file {filename}: {str(e)}\")\n",
        "\n",
        "        # Perform additional checks on x_data if needed\n",
        "        if len(self.x_data) == 0:\n",
        "            print(\"Warning: No data loaded. Check the integrity of your val files.\")\n",
        "\n",
        "\n",
        "        return training_list, validation_list\n",
        "\n",
        "\n",
        "    # for feeding dataset into model\n",
        "    def load_dataset(self, training_list):\n",
        "        \"\"\"\n",
        "        Loads the dataset in batches for training\n",
        "        :return: batch of data\n",
        "        \"\"\"\n",
        "        encoder_input_data = []\n",
        "        decoder_input_data = []\n",
        "        decoder_target_data = []\n",
        "        videoId = []\n",
        "        videoSeq = []\n",
        "\n",
        "        for idx, cap in enumerate(training_list):\n",
        "            caption = cap[0]\n",
        "            videoId.append(cap[1])\n",
        "            videoSeq.append(caption)\n",
        "\n",
        "        #tokenizing caption to be fed into encoder\n",
        "        train_sequences = self.tokenizer.texts_to_sequences(videoSeq)\n",
        "        train_sequences = np.array(train_sequences, dtype=object)\n",
        "\n",
        "        #pad captions to a max len of 10\n",
        "        train_sequences = pad_sequences(train_sequences, padding='post', truncating='post', maxlen=self.max_length)\n",
        "        file_size = len(train_sequences)\n",
        "\n",
        "        #create batches of data for feeding into the model\n",
        "        n = 0\n",
        "        for i in range(self.epochs):\n",
        "            for idx in range(0, file_size):\n",
        "                n += 1\n",
        "                encoder_input_data.append(self.x_data[videoId[idx]])\n",
        "                y = to_categorical(train_sequences[idx], self.num_decoder_tokens)\n",
        "                decoder_input_data.append(y[:-1])\n",
        "                decoder_target_data.append(y[1:])\n",
        "\n",
        "                if n == self.batch_size:\n",
        "                    encoder_input = np.array(encoder_input_data)\n",
        "                    decoder_input = np.array(decoder_input_data)\n",
        "                    decoder_target = np.array(decoder_target_data)\n",
        "                    encoder_input_data = []\n",
        "                    decoder_input_data = []\n",
        "                    decoder_target_data = []\n",
        "                    n = 0\n",
        "                    yield ([encoder_input, decoder_input], decoder_target)\n",
        "\n",
        "    def train_model(self):\n",
        "        \"\"\"\n",
        "        an encoder decoder sequence to sequence model\n",
        "        reference : https://arxiv.org/abs/1505.00487\n",
        "        \"\"\"\n",
        "        time_steps_encoder=80\n",
        "        num_encoder_tokens=4126\n",
        "        latent_dim=512\n",
        "        time_steps_decoder=10\n",
        "        num_decoder_tokens=3500\n",
        "        batch_size=6000\n",
        "\n",
        "        # Custom Attention Layer\n",
        "        attention = CustomAttention(name=\"custom_attention\")\n",
        "\n",
        "        # Encoder\n",
        "        encoder_inputs = Input(shape=(time_steps_encoder, num_encoder_tokens), name=\"encoder_inputs\")\n",
        "        print(encoder_inputs.shape)\n",
        "\n",
        "        attention_vector= attention(encoder_inputs)\n",
        "        print('attention vector shape', attention_vector.shape)\n",
        "\n",
        "        encoder = LSTM(latent_dim, return_state=True,return_sequences=True, name='endcoder_lstm')\n",
        "        encoder_outputs, state_h, state_c = encoder(attention_vector)\n",
        "        encoder_states = [state_h, state_c]\n",
        "\n",
        "        # Decoder\n",
        "        decoder_inputs = Input(shape=(time_steps_decoder, num_decoder_tokens), name=\"decoder_inputs\")\n",
        "        decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
        "        decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "        decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_relu')\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "        # Model\n",
        "        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "        model.summary()\n",
        "        training_list, validation_list = self.preprocessing()\n",
        "\n",
        "        train = self.load_dataset(training_list)\n",
        "        valid = self.load_dataset(validation_list)\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='min')\n",
        "\n",
        "        # Run training\n",
        "        opt = keras.optimizers.Adam(learning_rate=0.0003)\n",
        "        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                                      factor=0.1, patience=5, verbose=0,\n",
        "                                                      mode=\"auto\")\n",
        "        model.compile(metrics=['accuracy'], optimizer=opt, loss='categorical_crossentropy')\n",
        "\n",
        "        validation_steps = len(validation_list)//self.batch_size\n",
        "        steps_per_epoch = len(training_list)//self.batch_size\n",
        "        print('val len', len(validation_list))\n",
        "        print('train len', len(training_list))\n",
        "        print('val steps', validation_steps)\n",
        "        print('batch size', batch_size)\n",
        "        print('spe', steps_per_epoch)\n",
        "\n",
        "        attention_logger = AttentionLogger(attention_layer=attention)\n",
        "\n",
        "        model.fit(train, validation_data=valid, validation_steps=validation_steps,\n",
        "                  epochs=self.epochs, steps_per_epoch=steps_per_epoch,\n",
        "                  callbacks=[reduce_lr, early_stopping, attention_logger])\n",
        "\n",
        "        if not os.path.exists(self.save_model_path):\n",
        "            os.makedirs(self.save_model_path)\n",
        "\n",
        "        self.encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "        decoder_state_input_h = Input(shape=(self.latent_dim,))\n",
        "        decoder_state_input_c = Input(shape=(self.latent_dim,))\n",
        "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "        decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "            decoder_inputs, initial_state=decoder_states_inputs)\n",
        "        decoder_states = [state_h, state_c]\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "        self.decoder_model = Model(\n",
        "            [decoder_inputs] + decoder_states_inputs,\n",
        "            [decoder_outputs] + decoder_states)\n",
        "        self.encoder_model.summary()\n",
        "        self.decoder_model.summary()\n",
        "\n",
        "        # saving the models\n",
        "        self.encoder_model.save(os.path.join(self.save_model_path, 'encoder_model.h5'))\n",
        "        self.decoder_model.save_weights(os.path.join(self.save_model_path, 'decoder_model_weights.h5'))\n",
        "        with open(os.path.join(self.save_model_path, 'tokenizer' + str(self.num_decoder_tokens)), 'wb') as file:\n",
        "            joblib.dump(self.tokenizer, file)\n",
        "\n",
        "\n",
        "video_to_text = VideoDescriptionTrain()\n",
        "video_to_text.train_model()"
      ],
      "metadata": {
        "id": "OUH7JDLkhgQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ae33ed-a192-44c6-8921-f7edb794a3d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cal.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.9 cal.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnsA6AXJy7Ay",
        "outputId": "97bc8669-2d91-4e2a-a390-997ced7d6517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-23 06:53:04.547615: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-07-23 06:53:04.590267: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-07-23 06:53:04.590879: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-07-23 06:53:06.032108: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "(None, 80, 4126)\n",
            "80\n",
            "(None, 80, 4126)\n",
            "wt_inputs shapes\n",
            "(6000, 80, 4096)\n",
            "(6000, 80, 5)\n",
            "(6000, 80, 5)\n",
            "(6000, 80, 20)\n",
            "attention vector shape (6000, 80, 4126)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer  [(None, 80, 4126)]           0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " custom_attention (CustomAt  (6000, 80, 4126)             320       ['encoder_inputs[0][0]']      \n",
            " tention)                                                                                         \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer  [(None, 10, 3500)]           0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " endcoder_lstm (LSTM)        [(6000, 80, 512),            9500672   ['custom_attention[0][0]']    \n",
            "                              (6000, 512),                                                        \n",
            "                              (6000, 512)]                                                        \n",
            "                                                                                                  \n",
            " decoder_lstm (LSTM)         [(6000, 10, 512),            8218624   ['decoder_inputs[0][0]',      \n",
            "                              (6000, 512),                           'endcoder_lstm[0][1]',       \n",
            "                              (6000, 512)]                           'endcoder_lstm[0][2]']       \n",
            "                                                                                                  \n",
            " decoder_relu (Dense)        (6000, 10, 3500)             1795500   ['decoder_lstm[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19515116 (74.44 MB)\n",
            "Trainable params: 19515116 (74.44 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "val len 3247\n",
            "train len 36710\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "val len 3247\n",
            "train len 36710\n",
            "val steps 0\n",
            "batch size 6000\n",
            "spe 6\n",
            "Epoch 1/120\n",
            "(None, None, None)\n",
            "wt_inputs shapes\n",
            "(6000, None, 4096)\n",
            "(6000, 80, 5)\n",
            "(6000, 80, 5)\n",
            "(6000, 80, 20)\n",
            "(None, None, None)\n",
            "wt_inputs shapes\n",
            "(6000, None, 4096)\n",
            "(6000, 80, 5)\n",
            "(6000, 80, 5)\n",
            "(6000, 80, 20)\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.1324 - accuracy: 0.1988  WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
            "6/6 [==============================] - 2142s 352s/step - loss: 8.1324 - accuracy: 0.1988 - lr: 3.0000e-04\n",
            "Epoch 2/120\n",
            "6/6 [==============================] - ETA: 0s - loss: 7.5809 - accuracy: 0.3060  WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
            "6/6 [==============================] - 2076s 346s/step - loss: 7.5809 - accuracy: 0.3060 - lr: 3.0000e-04\n",
            "Epoch 3/120\n",
            "6/6 [==============================] - ETA: 0s - loss: 5.6914 - accuracy: 0.3049  WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
            "6/6 [==============================] - 2076s 346s/step - loss: 5.6914 - accuracy: 0.3049 - lr: 3.0000e-04\n",
            "Epoch 4/120\n",
            "6/6 [==============================] - ETA: 0s - loss: 4.3789 - accuracy: 0.3049  WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
            "6/6 [==============================] - 2072s 345s/step - loss: 4.3789 - accuracy: 0.3049 - lr: 3.0000e-04\n",
            "Epoch 5/120\n",
            "6/6 [==============================] - ETA: 0s - loss: 3.8230 - accuracy: 0.3087  WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
            "6/6 [==============================] - 2059s 343s/step - loss: 3.8230 - accuracy: 0.3087 - lr: 3.0000e-04\n",
            "Epoch 6/120\n",
            "4/6 [===================>..........] - ETA: 11:27 - loss: 3.7239 - accuracy: 0.3088"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_to_text = VideoDescriptionTrain()\n",
        "video_to_text.train_model()"
      ],
      "metadata": {
        "id": "hMLvnaWqxEQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6451bb0d-f540-440b-dfe7-3593e7244e09",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 80, 4126)\n",
            "80\n",
            "(None, 80, 4126)\n",
            "wt_inputs shapes\n",
            "(1, 80, 4096)\n",
            "(1, 80, 5)\n",
            "(1, 80, 5)\n",
            "(1, 80, 20)\n",
            "(80,)  hehe  Tensor(\"custom_attention/Slice:0\", shape=(1, 80, 4096), dtype=float32)\n",
            "(1, 80)  hehe 2 Tensor(\"custom_attention/Slice:0\", shape=(1, 80, 4096), dtype=float32)\n",
            "(1, 80, 4096)\n",
            "(1, 80, 5)\n",
            "(1, 80, 5)\n",
            "(1, 80, 20)\n",
            "final return (None, 80, 4126)\n",
            "attention vector shape (None, 80, 4126)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 80, 4126)]           0         []                            \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer  [(None, 10, 3500)]           0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " endcoder_lstm (LSTM)        [(None, 80, 512),            9500672   ['input_1[0][0]']             \n",
            "                              (None, 512),                                                        \n",
            "                              (None, 512)]                                                        \n",
            "                                                                                                  \n",
            " decoder_lstm (LSTM)         [(None, 10, 512),            8218624   ['decoder_inputs[0][0]',      \n",
            "                              (None, 512),                           'endcoder_lstm[1][1]',       \n",
            "                              (None, 512)]                           'endcoder_lstm[1][2]']       \n",
            "                                                                                                  \n",
            " decoder_relu (Dense)        (None, 10, 3500)             1795500   ['decoder_lstm[1][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19514796 (74.44 MB)\n",
            "Trainable params: 19514796 (74.44 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "val len 3247\n",
            "train len 36710\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "(80, 4126)\n",
            "val len 3247\n",
            "train len 36710\n",
            "val steps 10\n",
            "batch size 320\n",
            "spe 114\n",
            "Epoch 1/120\n",
            "114/114 [==============================] - 145s 1s/step - loss: 4.1747 - accuracy: 0.3633 - val_loss: 3.1696 - val_accuracy: 0.4667 - lr: 3.0000e-04\n",
            "Epoch 2/120\n",
            "114/114 [==============================] - 137s 1s/step - loss: 3.2868 - accuracy: 0.4509 - val_loss: 2.9788 - val_accuracy: 0.4792 - lr: 3.0000e-04\n",
            "Epoch 3/120\n",
            "114/114 [==============================] - 127s 1s/step - loss: 3.1108 - accuracy: 0.4704 - val_loss: 2.8707 - val_accuracy: 0.4982 - lr: 3.0000e-04\n",
            "Epoch 4/120\n",
            "114/114 [==============================] - 130s 1s/step - loss: 2.9621 - accuracy: 0.5057 - val_loss: 2.7339 - val_accuracy: 0.5533 - lr: 3.0000e-04\n",
            "Epoch 5/120\n",
            "114/114 [==============================] - 127s 1s/step - loss: 2.8115 - accuracy: 0.5384 - val_loss: 2.6329 - val_accuracy: 0.5653 - lr: 3.0000e-04\n",
            "Epoch 6/120\n",
            "114/114 [==============================] - 137s 1s/step - loss: 2.6957 - accuracy: 0.5538 - val_loss: 2.5570 - val_accuracy: 0.5747 - lr: 3.0000e-04\n",
            "Epoch 7/120\n",
            "114/114 [==============================] - 138s 1s/step - loss: 2.5857 - accuracy: 0.5661 - val_loss: 2.4933 - val_accuracy: 0.5776 - lr: 3.0000e-04\n",
            "Epoch 8/120\n",
            "114/114 [==============================] - 137s 1s/step - loss: 2.4961 - accuracy: 0.5758 - val_loss: 2.4435 - val_accuracy: 0.5834 - lr: 3.0000e-04\n",
            "Epoch 9/120\n",
            "114/114 [==============================] - 136s 1s/step - loss: 2.4122 - accuracy: 0.5852 - val_loss: 2.3968 - val_accuracy: 0.5892 - lr: 3.0000e-04\n",
            "Epoch 10/120\n",
            "114/114 [==============================] - 128s 1s/step - loss: 2.3331 - accuracy: 0.5917 - val_loss: 2.3748 - val_accuracy: 0.5910 - lr: 3.0000e-04\n",
            "Epoch 11/120\n",
            "114/114 [==============================] - 128s 1s/step - loss: 2.2568 - accuracy: 0.5987 - val_loss: 2.3258 - val_accuracy: 0.5964 - lr: 3.0000e-04\n",
            "Epoch 12/120\n",
            "114/114 [==============================] - 137s 1s/step - loss: 2.1822 - accuracy: 0.6071 - val_loss: 2.2902 - val_accuracy: 0.6018 - lr: 3.0000e-04\n",
            "Epoch 13/120\n",
            "114/114 [==============================] - 136s 1s/step - loss: 2.1183 - accuracy: 0.6127 - val_loss: 2.2570 - val_accuracy: 0.6035 - lr: 3.0000e-04\n",
            "Epoch 14/120\n",
            "114/114 [==============================] - 137s 1s/step - loss: 2.0628 - accuracy: 0.6189 - val_loss: 2.2378 - val_accuracy: 0.6061 - lr: 3.0000e-04\n",
            "Epoch 15/120\n",
            "114/114 [==============================] - 128s 1s/step - loss: 2.0050 - accuracy: 0.6241 - val_loss: 2.2322 - val_accuracy: 0.6071 - lr: 3.0000e-04\n",
            "Epoch 16/120\n",
            "114/114 [==============================] - 138s 1s/step - loss: 1.9471 - accuracy: 0.6306 - val_loss: 2.2040 - val_accuracy: 0.6119 - lr: 3.0000e-04\n",
            "Epoch 17/120\n",
            "114/114 [==============================] - 127s 1s/step - loss: 1.8950 - accuracy: 0.6367 - val_loss: 2.2038 - val_accuracy: 0.6134 - lr: 3.0000e-04\n",
            "Epoch 18/120\n",
            "114/114 [==============================] - 138s 1s/step - loss: 1.8399 - accuracy: 0.6440 - val_loss: 2.1818 - val_accuracy: 0.6135 - lr: 3.0000e-04\n",
            "Epoch 19/120\n",
            "114/114 [==============================] - 136s 1s/step - loss: 1.7844 - accuracy: 0.6528 - val_loss: 2.1489 - val_accuracy: 0.6165 - lr: 3.0000e-04\n",
            "Epoch 20/120\n",
            "114/114 [==============================] - 139s 1s/step - loss: 1.7374 - accuracy: 0.6590 - val_loss: 2.1564 - val_accuracy: 0.6150 - lr: 3.0000e-04\n",
            "Epoch 21/120\n",
            "114/114 [==============================] - 127s 1s/step - loss: 1.6891 - accuracy: 0.6652 - val_loss: 2.1554 - val_accuracy: 0.6140 - lr: 3.0000e-04\n",
            "Epoch 22/120\n",
            "114/114 [==============================] - 143s 1s/step - loss: 1.6496 - accuracy: 0.6709 - val_loss: 2.1560 - val_accuracy: 0.6183 - lr: 3.0000e-04\n",
            "Epoch 23/120\n",
            "114/114 [==============================] - 127s 1s/step - loss: 1.6112 - accuracy: 0.6752 - val_loss: 2.1694 - val_accuracy: 0.6111 - lr: 3.0000e-04\n",
            "Epoch 23: early stopping\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 80, 4126)]        0         \n",
            "                                                                 \n",
            " endcoder_lstm (LSTM)        [(None, 80, 512),         9500672   \n",
            "                              (None, 512),                       \n",
            "                              (None, 512)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9500672 (36.24 MB)\n",
            "Trainable params: 9500672 (36.24 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " decoder_inputs (InputLayer  [(None, 10, 3500)]           0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)        [(None, 512)]                0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 512)]                0         []                            \n",
            "                                                                                                  \n",
            " decoder_lstm (LSTM)         [(None, 10, 512),            8218624   ['decoder_inputs[0][0]',      \n",
            "                              (None, 512),                           'input_3[0][0]',             \n",
            "                              (None, 512)]                           'input_4[0][0]']             \n",
            "                                                                                                  \n",
            " decoder_relu (Dense)        (None, 10, 3500)             1795500   ['decoder_lstm[2][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10014124 (38.20 MB)\n",
            "Trainable params: 10014124 (38.20 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL FOR INFERENCE"
      ],
      "metadata": {
        "id": "SkTZh-RxpbWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.models import Model, load_model\n",
        "import joblib"
      ],
      "metadata": {
        "id": "PjekkkRLpcnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model_path = '/content/drive/Shareddrives/FYP-models/without_cust_vocab_3500'\n",
        "num_decoder_tokens = 3500\n",
        "latent_dim = 512"
      ],
      "metadata": {
        "id": "ITS21z51vGhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference_model():\n",
        "    \"\"\"Returns the model that will be used for inference\"\"\"\n",
        "    with open(os.path.join(save_model_path, 'tokenizer' + str(num_decoder_tokens)), 'rb') as file:\n",
        "        tokenizer = joblib.load(file)\n",
        "    # loading encoder model including the attention layer\n",
        "    inf_encoder_model = load_model(os.path.join(save_model_path, 'encoder_model.h5'), custom_objects={'CustomAttention': CustomAttention})\n",
        "\n",
        "    # Manually compile the encoder model\n",
        "    inf_encoder_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    # inference decoder model loading\n",
        "    decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "    decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "    decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h, state_c]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    inf_decoder_model = Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "    inf_decoder_model.load_weights(os.path.join(save_model_path, 'decoder_model_weights.h5'))\n",
        "    return tokenizer, inf_encoder_model, inf_decoder_model\n"
      ],
      "metadata": {
        "id": "J_0IfIXtvAYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING\n"
      ],
      "metadata": {
        "id": "wNb_Fj35vM5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMPORTS"
      ],
      "metadata": {
        "id": "KCRqmwqsvfeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dill\n",
        "!pip show h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37XKkiT9vTtM",
        "outputId": "052819dc-3189-4398-da76-7c0e36a395d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dill\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m112.6/116.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill\n",
            "Successfully installed dill-0.3.8\n",
            "Name: h5py\n",
            "Version: 3.9.0\n",
            "Summary: Read and write HDF5 files from Python\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Andrew Collette <andrew.collette@gmail.com>\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy\n",
            "Required-by: h5netcdf, tensorflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import operator\n",
        "import os\n",
        "import time\n",
        "import h5py\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "EszZAWmvvXuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "!pip install ultralytics\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKCsfZWxvn81",
        "outputId": "bc448dea-d2d3-4193-b35d-6164a03220a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.0-py3-none-any.whl (750 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/750.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/750.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m747.5/750.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.8/750.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FEAT EXTRACTION FOR NEW VIDEOS"
      ],
      "metadata": {
        "id": "8bqWfqbivZyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting video clip into frames\n",
        "# returns list of frame names\n",
        "\n",
        "def video_to_frames(video):\n",
        "    path = os.path.join(test_path, 'temporary_images')\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path)\n",
        "    os.makedirs(path)\n",
        "    video_path = os.path.join(test_path, 'video', video)\n",
        "    count = 0\n",
        "    image_list = []\n",
        "\n",
        "    # Path to video file\n",
        "    print(\"Video path\", video_path)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if ret is False:\n",
        "            break\n",
        "        cv2.imwrite(os.path.join(test_path, 'temporary_images', 'frame%d.jpg' % count), frame)\n",
        "        image_list.append(os.path.join(test_path, 'temporary_images', 'frame%d.jpg' % count))\n",
        "        count += 1\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print('Frames extracted')\n",
        "    return image_list\n"
      ],
      "metadata": {
        "id": "FulySccCv3m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGG16 CNN MODEL"
      ],
      "metadata": {
        "id": "kzkc2WsFv7Os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_cnn_load():\n",
        "    model = VGG16(weights=\"imagenet\", include_top=True, input_shape=(224, 224, 3))\n",
        "    out = model.layers[-2].output\n",
        "    model_final = Model(inputs=model.input, outputs=out)\n",
        "    return model_final\n",
        "\n",
        "def load_image(path):\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    return img"
      ],
      "metadata": {
        "id": "FZJ8a3HwwJiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### YOLOv8 OBJECT DETECTION MODEL"
      ],
      "metadata": {
        "id": "3PEorV-iwLQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_model_name = \"yolov8n.pt\"\n",
        "yolo_model = YOLO(yolo_model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x-Ag9PJwQCR",
        "outputId": "07dd9338-294f-4c67-80af-df25a5b2f842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 87.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features for each video\n",
        "\n",
        "def extract_features(video, model):\n",
        "    \"\"\"\n",
        "    :param video: The video whose frames are to be extracted to convert into a numpy array\n",
        "    :param model: the pretrained vgg16 model\n",
        "    :return: numpy array of size 4096x80\n",
        "    \"\"\"\n",
        "    video_id = video.split(\".\")[0]\n",
        "    print(video_id)\n",
        "    print(f'Processing video {video}')\n",
        "\n",
        "    image_list = video_to_frames(video) #get frame list for the video\n",
        "    print(image_list)\n",
        "    samples = np.round(np.linspace(0, len(image_list) - 1, 80))\n",
        "    image_list = [image_list[int(sample)] for sample in samples]\n",
        "    images = np.zeros((len(image_list), 224, 224, 3))\n",
        "    print('Something wrong here?')\n",
        "\n",
        "    yolo_img_feats = np.array([]) #contains (6*5) * 80 elements\n",
        "\n",
        "    for i in range(len(image_list)):\n",
        "        img = load_image(image_list[i])\n",
        "        images[i] = img\n",
        "        print('here?')\n",
        "        # object detection\n",
        "        results = yolo_model.predict(source=images[i], save=True) # single frame, many objects\n",
        "        out_list = []\n",
        "        out = results[0].boxes.data.tolist() # list of detected objects for 1 frame\n",
        "        for r in out:\n",
        "          if r[-1] == 0:\n",
        "            r[-1] = 80\n",
        "          out_list.append(r)\n",
        "\n",
        "        while len(out_list) < 6:\n",
        "          out_list.append([0, 0, 0, 0, 0, 0])\n",
        "\n",
        "        print(out_list)\n",
        "\n",
        "        # sorting the list based on score and taking first 5 objects\n",
        "        sorted_out_list = sorted(out_list, key=lambda x: x[4], reverse=True)[:5]\n",
        "        print(sorted_out_list)\n",
        "        sorted_array = np.array(sorted_out_list).flatten() #1D array of obj detection info - each frame i (30)\n",
        "        print('sorted array', sorted_array)\n",
        "        yolo_img_feats = np.append(yolo_img_feats, sorted_array)\n",
        "\n",
        "    images = np.array(images)\n",
        "    fc_feats = model.predict(images, batch_size=128)\n",
        "    img_feats = np.array(fc_feats)\n",
        "\n",
        "    # deleting the frame image files\n",
        "    temp_images_dir = os.path.join(test_path, 'temporary_images')\n",
        "    try:\n",
        "      shutil.rmtree(temp_images_dir)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Directory '{temp_images_dir}' not found.\")\n",
        "    print('Both features extracted!!')\n",
        "    return (img_feats, yolo_img_feats)\n"
      ],
      "metadata": {
        "id": "zuZXwvGtwtt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saves the numpy features from all the videos. Passes videos one by one to extract_features() fn, and saves the received features into npy file\n",
        "\n",
        "def extract_feats_pretrained_cnn():\n",
        "    model = model_cnn_load()\n",
        "    print('VGG16 model loaded')\n",
        "\n",
        "    if not os.path.isdir(os.path.join(test_path, 'feat')):\n",
        "        os.mkdir(os.path.join(test_path, 'feat'))\n",
        "    if not os.path.isdir(os.path.join(test_path, 'yolo-feat')):\n",
        "        os.mkdir(os.path.join(test_path, 'yolo-feat'))\n",
        "\n",
        "    video_list = os.listdir(os.path.join(test_path, 'video'))\n",
        "    for video in video_list:\n",
        "        video_name = video.split(\".\")[0]\n",
        "        npy_file = os.path.join(test_path, 'feat', video_name + '.npy')\n",
        "        yolo_npy_file = os.path.join(test_path, 'yolo-feat', video_name + '.npy')\n",
        "\n",
        "        # Check if corresponding .npy file already exists\n",
        "        if os.path.exists(npy_file) and os.path.exists(yolo_npy_file):\n",
        "            print(f\"Skipping {video_name} as features already exist.\")\n",
        "            continue\n",
        "\n",
        "        # Extract features for the video and save into feat folder\n",
        "        img_feats, yolo_img_feats = extract_features(video, model)\n",
        "        np.save(npy_file, img_feats)\n",
        "        np.save(yolo_npy_file, yolo_img_feats)"
      ],
      "metadata": {
        "id": "i6fLbVI-wxWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TEST VIDEO CAPTIONING"
      ],
      "metadata": {
        "id": "en6d2pqCwzZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H08xHhkCw1D6",
        "outputId": "97aaa316-7d00-42f1-cc6b-ea49d828cc12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import functools\n",
        "import operator\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "rS5lopD_w3as"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_video_source = [\"production_id_3969532.mp4\", \"production_id_4624594.mp4\"]\n",
        "#test_video_source = [\"rainy_street.avi\"]\n",
        "test_video_source = ['zzit5b_-ukg_5_20']\n",
        "test_video_source"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmlsfSGvw5nU",
        "outputId": "6a31e098-5ce4-4d0e-8c59-3d6a885b4574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['zzit5b_-ukg_5_20']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VideoDescriptionRealTime(object):\n",
        "    \"\"\"\n",
        "        Initialize the parameters for the model\n",
        "        \"\"\"\n",
        "    def __init__(self):\n",
        "        self.latent_dim = 512\n",
        "        self.num_encoder_tokens = 4126\n",
        "        self.num_decoder_tokens = 3500\n",
        "        self.time_steps_encoder = 80\n",
        "        self.max_probability = -1\n",
        "\n",
        "        # models\n",
        "        self.tokenizer, self.inf_encoder_model,  self.inf_decoder_model = inference_model()\n",
        "        self.test_features_path = test_features_path\n",
        "        self.test_video_source = test_video_source\n",
        "        self.search_type = 'greedy'\n",
        "       #self.inf_decoder_model = None\n",
        "        self.num = 0\n",
        "\n",
        "    def greedy_search(self, loaded_array):\n",
        "        \"\"\"\n",
        "\n",
        "        :param f: the loaded numpy array after creating videos to frames and extracting features\n",
        "        :return: the final sentence which has been predicted greedily\n",
        "        \"\"\"\n",
        "        inv_map = self.index_to_word()\n",
        "        states_value = self.inf_encoder_model.predict(loaded_array.reshape(-1, 80, 4126))\n",
        "        target_seq = np.zeros((1, 1, 3500))\n",
        "        final_sentence = ''\n",
        "        target_seq[0, 0, self.tokenizer.word_index['bos']] = 1\n",
        "        for i in range(15):\n",
        "            output_tokens, h, c = self.inf_decoder_model.predict([target_seq] + states_value)\n",
        "            states_value = [h, c]\n",
        "            output_tokens = output_tokens.reshape(self.num_decoder_tokens)\n",
        "            y_hat = np.argmax(output_tokens)\n",
        "            if y_hat == 0:\n",
        "                continue\n",
        "            if inv_map[y_hat] is None:\n",
        "                break\n",
        "            if inv_map[y_hat] == 'eos':\n",
        "                break\n",
        "            else:\n",
        "                final_sentence = final_sentence + inv_map[y_hat] + ' '\n",
        "                target_seq = np.zeros((1, 1, 3500))\n",
        "                target_seq[0, 0, y_hat] = 1\n",
        "        return final_sentence\n",
        "\n",
        "    def decode_sequence2bs(self, input_seq):\n",
        "        states_value = self.inf_encoder_model.predict(input_seq)\n",
        "        target_seq = np.zeros((1, 1, self.num_decoder_tokens))\n",
        "        target_seq[0, 0, self.tokenizer.word_index['bos']] = 1\n",
        "        self.beam_search(target_seq, states_value, [], [], 0)\n",
        "        return decode_seq\n",
        "\n",
        "    def beam_search(self, target_seq, states_value, prob, path, lens):\n",
        "        \"\"\"\n",
        "\n",
        "        :param target_seq: the array that is fed into the model to predict the next word\n",
        "        :param states_value: previous state that is fed into the lstm cell\n",
        "        :param prob: probability of predicting a word\n",
        "        :param path: list of words from each sentence\n",
        "        :param lens: number of words\n",
        "        :return: final sentence\n",
        "        \"\"\"\n",
        "        global decode_seq\n",
        "        node = 2\n",
        "        output_tokens, h, c = self.inf_decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "        output_tokens = output_tokens.reshape(self.num_decoder_tokens)\n",
        "        sampled_token_index = output_tokens.argsort()[-node:][::-1]\n",
        "        states_value = [h, c]\n",
        "        for i in range(node):\n",
        "            if sampled_token_index[i] == 0:\n",
        "                sampled_char = ''\n",
        "            else:\n",
        "                sampled_char = list(self.tokenizer.word_index.keys())[\n",
        "                    list(self.tokenizer.word_index.values()).index(sampled_token_index[i])]\n",
        "            MAX_LEN = 12\n",
        "            if sampled_char != 'eos' and lens <= MAX_LEN:\n",
        "                p = output_tokens[sampled_token_index[i]]\n",
        "                if sampled_char == '':\n",
        "                    p = 1\n",
        "                prob_new = list(prob)\n",
        "                prob_new.append(p)\n",
        "                path_new = list(path)\n",
        "                path_new.append(sampled_char)\n",
        "                target_seq = np.zeros((1, 1, self.num_decoder_tokens))\n",
        "                target_seq[0, 0, sampled_token_index[i]] = 1.\n",
        "                self.beam_search(target_seq, states_value, prob_new, path_new, lens + 1)\n",
        "            else:\n",
        "                p = output_tokens[sampled_token_index[i]]\n",
        "                prob_new = list(prob)\n",
        "                prob_new.append(p)\n",
        "                p = functools.reduce(operator.mul, prob_new, 1)\n",
        "                if p > self.max_probability:\n",
        "                    decode_seq = path\n",
        "                    self.max_probability = p\n",
        "\n",
        "    def decoded_sentence_tuning(self, decoded_sentence):\n",
        "        # tuning sentence\n",
        "        decode_str = []\n",
        "        filter_string = ['bos', 'eos']\n",
        "        uni_gram = {}\n",
        "        last_string = \"\"\n",
        "        for idx2, c in enumerate(decoded_sentence):\n",
        "            if c in uni_gram:\n",
        "                uni_gram[c] += 1\n",
        "            else:\n",
        "                uni_gram[c] = 1\n",
        "            if last_string == c and idx2 > 0:\n",
        "                continue\n",
        "            if c in filter_string:\n",
        "                continue\n",
        "            if len(c) > 0:\n",
        "                decode_str.append(c)\n",
        "            if idx2 > 0:\n",
        "                last_string = c\n",
        "        return decode_str\n",
        "\n",
        "    def index_to_word(self):\n",
        "        # inverts word tokenizer\n",
        "        index_to_word = {value: key for key, value in self.tokenizer.word_index.items()}\n",
        "        return index_to_word\n",
        "\n",
        "    def get_test_data(self):\n",
        "        file_name = test_video_source[self.num]\n",
        "\n",
        "        # split video here\n",
        "\n",
        "        # getting features for the test video\n",
        "        print('feat', self.test_features_path, 'file',file_name)\n",
        "        cnn_path = os.path.join(self.test_features_path, 'feat', file_name + '.npy')\n",
        "        yolo_path = os.path.join(self.test_features_path, 'yolo-feat', file_name + '.npy')\n",
        "\n",
        "        if os.path.exists(cnn_path) and os.path.exists(yolo_path): #features exist\n",
        "            cnn_f = np.load(cnn_path)\n",
        "            yolo_f = np.load(yolo_path)\n",
        "        else:  #extract features\n",
        "            model = model_cnn_load()\n",
        "            print(\"model loaded\")\n",
        "            cnn_f, yolo_f = extract_features(file_name, model)\n",
        "            print(\"features extracted\")\n",
        "            print(cnn_f)\n",
        "            print(yolo_f)\n",
        "\n",
        "        if self.num < 1:\n",
        "            self.num += 1\n",
        "        else:\n",
        "            self.num = 0\n",
        "        return cnn_f, yolo_f, file_name\n",
        "\n",
        "    def test(self):\n",
        "        cnn_f, yolo_f, filename = self.get_test_data()\n",
        "        print('cnn_f:', cnn_f.shape)\n",
        "        print('yolo_f:', yolo_f.shape)\n",
        "        yolo_f = yolo_f.reshape(-1, 30)\n",
        "        print('Converted yolo features to', yolo_f.shape)\n",
        "\n",
        "        #concatenate arrays\n",
        "        combined_f = np.concatenate((cnn_f, yolo_f), axis=1)\n",
        "        print(combined_f.shape)\n",
        "\n",
        "        # generate inference test outputs\n",
        "        if self.search_type == 'greedy':\n",
        "            sentence_predicted = self.greedy_search(combined_f.reshape((-1, 80, 4126)))\n",
        "        else:\n",
        "            sentence_predicted = ''\n",
        "            decoded_sentence = self.decode_sequence2bs(combined_f.reshape((-1, 80, 4126)))\n",
        "            decode_str = self.decoded_sentence_tuning(decoded_sentence)\n",
        "            for d in decode_str:\n",
        "                sentence_predicted = sentence_predicted + d + ' '\n",
        "        # re-init max prob\n",
        "        self.max_probability = -1\n",
        "        print(\"caption generated:\", sentence_predicted)\n",
        "        return sentence_predicted, filename\n",
        "\n",
        "    def main(self, filename, caption):\n",
        "        \"\"\"\n",
        "\n",
        "        :param filename: the video to load\n",
        "        :param caption: final caption\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"video:\", filename) # video file name gets printed\n",
        "\n",
        "        #cap = cv2.VideoCapture(os.path.join(self.test_path, 'real-time-video', filename))\n",
        "        cap = cv2.VideoCapture(filename)\n",
        "\n",
        "        # read first frame\n",
        "        frame_count = 0\n",
        "        ret, frame = cap.read()\n",
        "        frame_count += 1\n",
        "        print(ret, frame_count)\n",
        "        if not ret:\n",
        "          print(\"not read\")\n",
        "\n",
        "        # get frame rate of input video\n",
        "        frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        print(frame_rate)\n",
        "\n",
        "        # get frame size of input video\n",
        "        frame_size = (frame.shape[1], frame.shape[0])\n",
        "        print(frame_size)\n",
        "\n",
        "        # set output caption settings\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        font_scale = 1\n",
        "        colour = (255, 255, 255) #white\n",
        "        font_width = 2\n",
        "          # get boundary of the caption text\n",
        "        textsize = cv2.getTextSize(caption, font, 1, 2)[0]\n",
        "          # get coords based on boundary\n",
        "        textX = (frame_size[0] - textsize[0]) // 2\n",
        "        textY = (frame_size[1] + textsize[1]) // 2\n",
        "        caption_position = (textX, textY)\n",
        "\n",
        "        # set output video format with encodings\n",
        "        #format_fourcc = cv2.VideoWriter_fourcc('X','V','I','D') # for avi format\n",
        "        format_fourcc = cv2.VideoWriter_fourcc(*'MP4V') # for mp4 format\n",
        "\n",
        "        # initiate writing result video to output path\n",
        "        video_output_path = os.path.join(output_path, filename)\n",
        "        cap_output = cv2.VideoWriter(video_output_path, format_fourcc, frame_rate, frame_size)\n",
        "\n",
        "        # attach captions to output video\n",
        "        ret = True\n",
        "        while ret:\n",
        "          cv2.putText(frame, caption, (textX, textY), font, font_scale, colour, font_width)\n",
        "\n",
        "          if (cv2.waitKey(30) == 27):\n",
        "            break\n",
        "\n",
        "          #add captioned frame to output video\n",
        "          cap_output.write(frame)\n",
        "\n",
        "          #read next frame\n",
        "          ret, frame = cap.read()\n",
        "          frame_count += 1\n",
        "          print(ret, frame_count)\n",
        "\n",
        "        cap.release()\n",
        "        cap_output.release()\n"
      ],
      "metadata": {
        "id": "X-IbBxmBu5Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write captions to the"
      ],
      "metadata": {
        "id": "1mG9_49F1tAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    video_to_text = VideoDescriptionRealTime()\n",
        "    while True:\n",
        "        print('.........................\\nGenerating Caption:\\n')\n",
        "        try:\n",
        "          start = time.time()\n",
        "          video_caption, file = video_to_text.test()\n",
        "          end = time.time()\n",
        "          print('Caption:', video_caption)\n",
        "          # video_to_text.main(file, video_caption)\n",
        "\n",
        "        except IndexError:\n",
        "          print(\"Execution complete!\")\n",
        "          break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvIDPBb3xjTu",
        "outputId": "9f41cb4b-289e-4f20-d525-1afa7e6c7e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".........................\n",
            "Generating Caption:\n",
            "\n",
            "feat /content/drive/Shareddrives/msvd-test-feats/test/custom_feat file zzit5b_-ukg_5_20\n",
            "cnn_f: (80, 4096)\n",
            "yolo_f: (2400,)\n",
            "Converted yolo features to (80, 30)\n",
            "(80, 4126)\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 739ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "caption generated: a person is eating \n",
            "Caption: a person is eating \n",
            ".........................\n",
            "Generating Caption:\n",
            "\n",
            "Execution complete!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8bqWfqbivZyb"
      ],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
